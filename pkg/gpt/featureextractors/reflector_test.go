package featureextractors

import (
	"context"
	"fmt"
	"testing"

	"github.com/greenboxal/aip/aip-controller/pkg/collective/msn"
	"github.com/stretchr/testify/require"

	"github.com/greenboxal/agibootstrap/pkg/platform/db/thoughtstream"
)

func TestReflector(t *testing.T) {
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	history := []*thoughtstream.Thought{
		{
			From: thoughtstream.CommHandle{
				Name: "Singularity",
				Role: msn.RoleAI,
			},

			Text: "To accomplish this task, we'll need the expertise of several agents. Let's start by involving the following agents:\\n\\n- **Director**: to establish the task's overarching goal and key objectives.\\n- **Strategist**: to devise an efficient roadmap for the task, breaking down the goal into manageable steps and providing a clear plan of action.\\n- **TopDownCoder**: to implement the lexer/parser logic in Go.\\n- **QATester**: to scrutinize the code and ensure it meets the required standards and functionality.\\n\\nI will now assign the task to the Director agent.",
		},
	}

	res, reply, err := Reflect[Routing](ctx, ReflectOptions{
		History: history,

		Query: "The message above contains requests, commands, questions or replies to one or more users/agents/recipients. Please split the message with the relevant details for each individual subject.",

		ExampleInput: "Everyone pay attention! Bob do this and do that, and have Carol assist you. Carol also learn Y meanwhile. Alice write some reports afterwards.",

		ExampleOutput: Routing{
			Recipients: map[string][]string{
				"Bob":   {"Do this", "Do that"},
				"Carol": {"Assist Bob on X", "Learn Y"},
				"Alice": {"Write some reports"},
				"*":     {"Everyone please pay attention!"},
			},
		},
	})

	require.NoError(t, err)
	require.NotEmpty(t, reply.Entries)

	fmt.Printf("%+v\n", res)
}

func TestQueryPlan(t *testing.T) {
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	history := []*thoughtstream.Thought{
		{
			From: thoughtstream.CommHandle{
				Name: "Singularity",
				Role: msn.RoleAI,
			},

			Text: `
The task at hand is to write a lexer/parser in Go that can parse Python 2/3 code into an Abstract Syntax Tree (AST). The AST will be represented using a set of struct types, with each struct representing a different type of AST node.

The critical milestones for this task can be outlined as follows:

1. Understand the Python 2/3 syntax: Gain a comprehensive understanding of the Python 2 and Python 3 syntax to accurately parse and build the AST.
2. Design the AST node struct types: Define a set of struct types in Go, with each struct type representing a different type of AST node. These struct types will store relevant information and relationships between nodes in the AST.
3. Implement the lexer: Develop a lexer in Go that can tokenize the input Python code into meaningful tokens that can be used in the parser.
4. Implement the parser: Implement the parser logic, which takes the tokens generated by the lexer and constructs an AST based on the Python code's syntax and structure.
5. Test and refine the code: Conduct thorough testing to ensure that the lexer/parser functions correctly and accurately generates the desired AST for a range of Python code inputs.
6. Document the code: Create comprehensive documentation that explains the purpose, usage, and internal workings of the lexer/parser implementation.
`,
		},
	}

	plan, err := QueryPlan(ctx, history)

	require.NoError(t, err)
	require.NotEmpty(t, plan.Steps)

	fmt.Printf("%+v\n", plan)
}

func TestSentiment(t *testing.T) {
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	history := []*thoughtstream.Thought{
		{
			From: thoughtstream.CommHandle{
				Name: "Singularity",
				Role: msn.RoleAI,
			},

			Text: `
The task at hand is to write a lexer/parser in Go that can parse Python 2/3 code into an Abstract Syntax Tree (AST). The AST will be represented using a set of struct types, with each struct representing a different type of AST node.

The critical milestones for this task can be outlined as follows:

1. Understand the Python 2/3 syntax: Gain a comprehensive understanding of the Python 2 and Python 3 syntax to accurately parse and build the AST.
2. Design the AST node struct types: Define a set of struct types in Go, with each struct type representing a different type of AST node. These struct types will store relevant information and relationships between nodes in the AST.
3. Implement the lexer: Develop a lexer in Go that can tokenize the input Python code into meaningful tokens that can be used in the parser.
4. Implement the parser: Implement the parser logic, which takes the tokens generated by the lexer and constructs an AST based on the Python code's syntax and structure.
5. Test and refine the code: Conduct thorough testing to ensure that the lexer/parser functions correctly and accurately generates the desired AST for a range of Python code inputs.
6. Document the code: Create comprehensive documentation that explains the purpose, usage, and internal workings of the lexer/parser implementation.
`,
		},
	}

	plan, err := QueryPlan(ctx, history)

	require.NoError(t, err)
	require.NotEmpty(t, plan.Steps)

	fmt.Printf("%+v\n", plan)
}

func TestGoalCompletion(t *testing.T) {
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	history := []*thoughtstream.Thought{
		{
			From: thoughtstream.CommHandle{
				Name: "Singularity",
				Role: msn.RoleAI,
			},

			Text: `
The task at hand is to write a lexer/parser in Go that can parse Python 2/3 code into an Abstract Syntax Tree (AST). The AST will be represented using a set of struct types, with each struct representing a different type of AST node.

The critical milestones for this task can be outlined as follows:

1. Understand the Python 2/3 syntax: Gain a comprehensive understanding of the Python 2 and Python 3 syntax to accurately parse and build the AST.
2. Design the AST node struct types: Define a set of struct types in Go, with each struct type representing a different type of AST node. These struct types will store relevant information and relationships between nodes in the AST.
3. Implement the lexer: Develop a lexer in Go that can tokenize the input Python code into meaningful tokens that can be used in the parser.
4. Implement the parser: Implement the parser logic, which takes the tokens generated by the lexer and constructs an AST based on the Python code's syntax and structure.
5. Test and refine the code: Conduct thorough testing to ensure that the lexer/parser functions correctly and accurately generates the desired AST for a range of Python code inputs.
6. Document the code: Create comprehensive documentation that explains the purpose, usage, and internal workings of the lexer/parser implementation.
`,
		},
	}

	plan, err := QueryGoalCompletion(ctx, history)

	require.NoError(t, err)

	fmt.Printf("%+v\n", plan)
}
